[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de datos",
    "section": "",
    "text": "Para llevar acabo esta investigación, Data Crítica recolectó datos utilizando la API Académica de Twitter y la herramienta Minet. El periodo de los tweets recolectados abarca desde la creación de cada uno de los perfiles seleccionados hasta el 21 de marzo de 2023. Los textos de los tweets fueron clasificados programáticamente utilizando modelado de tópicos con la librería de Python BERTopic para generar clusters con temas fácilmente interpretables.\nPosteriormente se entrenó el modelo con el texto de los tweets sin procesar y preprocesados para explorar lo resultados. Sin embargo, se interpretaron mejor los tópicos utilizando texto preprocesado, ya que las palabras catalogadas como stop-words causaron mucho ruido en los tópicos entrenados con el texto original. Asimismo, se utilizó un modelo multilingual debido a que los datos se encuentran en español y portugués.\nDespués de adaptar el modelo a los datos, se extrajeron los tópicos generados y se visualizaron de una manera muy similar al metodo LDavis. Para las cuentas en las que se generaron 50 o menos tópicos, se mantuvieron tal cual. No obstante, para las cuentas donde se obtuvieron más de 50, se realizó una reducción de tópicos al 20% del total identificados. Este procedimiento se aplicó debido a que es difícil predecir el número de tópicos antes de haber entrenado el modelo, de ahí que se pueda decidir un número de temas después de saber cuántos se crean en un principio. Además, el propósito es poder identificar aquellos tópicos relacionados con temas de género, por ello es más asequible reducir esta cantidad para poder categorizarlos.\nPara visualizar los términos asociados a cada tópico, se crearon gráficos de barras con las puntuaciones c-TF-IDF de cada tópico. Posteriormente se analizó tópico por tópico y se seleccionaron aquellos que hablan sobre aborto, feminismo, género y personas LGBTIQ+. Luego se hizo un lista de palabras con los términos asociados con esos tópicos y se filtraron los tweets de cada cuenta que contenían alguna de esas palabras, esto con el objetivo de hacer una aproximación de la cantidad de tweets de cada cuenta que tocan estos temas. Finalmente se calculó el porcentaje de tweets filtrados con temática de género entre el total de tweets para cada cuenta.\nPara más detalles sobre los tópicos generados y su selección, revisar el apartado correspondiente para cada cuenta."
  },
  {
    "objectID": "index.html#metodología",
    "href": "index.html#metodología",
    "title": "Análisis de datos",
    "section": "",
    "text": "Para llevar acabo esta investigación, Data Crítica recolectó datos utilizando la API Académica de Twitter y la herramienta Minet. El periodo de los tweets recolectados abarca desde la creación de cada uno de los perfiles seleccionados hasta el 21 de marzo de 2023. Los textos de los tweets fueron clasificados programáticamente utilizando modelado de tópicos con la librería de Python BERTopic para generar clusters con temas fácilmente interpretables.\nPosteriormente se entrenó el modelo con el texto de los tweets sin procesar y preprocesados para explorar lo resultados. Sin embargo, se interpretaron mejor los tópicos utilizando texto preprocesado, ya que las palabras catalogadas como stop-words causaron mucho ruido en los tópicos entrenados con el texto original. Asimismo, se utilizó un modelo multilingual debido a que los datos se encuentran en español y portugués.\nDespués de adaptar el modelo a los datos, se extrajeron los tópicos generados y se visualizaron de una manera muy similar al metodo LDavis. Para las cuentas en las que se generaron 50 o menos tópicos, se mantuvieron tal cual. No obstante, para las cuentas donde se obtuvieron más de 50, se realizó una reducción de tópicos al 20% del total identificados. Este procedimiento se aplicó debido a que es difícil predecir el número de tópicos antes de haber entrenado el modelo, de ahí que se pueda decidir un número de temas después de saber cuántos se crean en un principio. Además, el propósito es poder identificar aquellos tópicos relacionados con temas de género, por ello es más asequible reducir esta cantidad para poder categorizarlos.\nPara visualizar los términos asociados a cada tópico, se crearon gráficos de barras con las puntuaciones c-TF-IDF de cada tópico. Posteriormente se analizó tópico por tópico y se seleccionaron aquellos que hablan sobre aborto, feminismo, género y personas LGBTIQ+. Luego se hizo un lista de palabras con los términos asociados con esos tópicos y se filtraron los tweets de cada cuenta que contenían alguna de esas palabras, esto con el objetivo de hacer una aproximación de la cantidad de tweets de cada cuenta que tocan estos temas. Finalmente se calculó el porcentaje de tweets filtrados con temática de género entre el total de tweets para cada cuenta.\nPara más detalles sobre los tópicos generados y su selección, revisar el apartado correspondiente para cada cuenta."
  },
  {
    "objectID": "index.html#instalación",
    "href": "index.html#instalación",
    "title": "Análisis de datos",
    "section": "Instalación",
    "text": "Instalación\nLista de librerías requeridas para el proyecto:\npip install minet\npip install pandas\npip install numpy\npip install plotly\npip install emoji\npip install spacy\npip install tweet-preprocessor\npip install bertopic\npython -m spacy download es_core_news_sm\npython -m spacy download pt_core_news_sm"
  },
  {
    "objectID": "index.html#documentación",
    "href": "index.html#documentación",
    "title": "Análisis de datos",
    "section": "Documentación",
    "text": "Documentación\nLista de documentación para las librerías requeridas:\n\nminet\npandas\nnumpy\nplotly\nemoji\nspacy\npreprocessor\nbertopic"
  },
  {
    "objectID": "index.html#selección-de-perfiles",
    "href": "index.html#selección-de-perfiles",
    "title": "Análisis de datos",
    "section": "Selección de perfiles",
    "text": "Selección de perfiles\nSe seleccionaron 3 cuentas por cada país incluyendo organizaciones provida, así como figuras políticas y religiosas de Brasil, Colombia y Ecuador.\n\n\n\nPaís\nNombre\nUsuario\n\n\n\n\nBrasil\nNikolas Ferreira\nnikolas_dm\n\n\nBrasil\nPastor Silas Malafaia\nPastorMalafaia\n\n\nBrasil\nBrasil Sem Aborto\nbrasilsemaborto\n\n\nColombia\nMisión Paz\nmisionpaz\n\n\nColombia\nMaría Fernanda Cabal\nMariaFdaCabal\n\n\nColombia\nUnidos por la Vida\nUnidosxlaVidaCo\n\n\nEcuador\nMamela Fiallo Flor\nMamelaFialloFlo\n\n\nEcuador\nEsteban Torres Cobo\netorrescobo\n\n\nEcuador\nFamilia Ecuador\n_FamiliaEcuador"
  },
  {
    "objectID": "index.html#recolección-de-datos",
    "href": "index.html#recolección-de-datos",
    "title": "Análisis de datos",
    "section": "Recolección de datos",
    "text": "Recolección de datos\nSe recolectaron los tweets de cada usuario usando la librería minet como interfaz de línea de comandos (CLI)\nminet twitter scrape tweets 'from:username' &gt; username.csv"
  },
  {
    "objectID": "index.html#preprocesamiento",
    "href": "index.html#preprocesamiento",
    "title": "Análisis de datos",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\nSe aplicaron varias técnicas de preprocesamiento de texto en los datos con las librerías preprocessor y spacy:\n\nLower: Todas las palabras se convirtieron a minúsculas (p.e: Twitter → twitter)\nStop words: Se eliminaron las palabras que son muy comunes pero que no aportan significado al texto. Se utilizaron las que vienen por defecto para español y portugués en spacy.\nDemojize: Cambia los emojis por una representación textual (p.e: relaxed → :smiling_face:)\nURLs: Sustituye las URLs por $URL$ (p.e: https://github.com/ → $URL$)\nMentions: Sustituye las menciones por $MENTION$ (p.e: @twitter → $MENTION$)\nHashtags: Sustituye los hashtags por $HASHTAG$ (p.e: #twitter → $HASHTAG$)\nNúmeros: Sustituye los números por $NUMBER$ (p.e: 4 → $NUMBER$)"
  },
  {
    "objectID": "index.html#modelado-de-tópicos",
    "href": "index.html#modelado-de-tópicos",
    "title": "Análisis de datos",
    "section": "Modelado de tópicos",
    "text": "Modelado de tópicos\nPara el modelado de tópicos se utilizó la librería bertopic que utiliza técnicas de embeddings con Transformers y c-TF-IDF. Por defecto, los pasos principales para el modelado de temas con BERTopic son Sentence Transformers, UMAP, HDBSCAN y c-TF-IDF ejecutados en secuencia."
  },
  {
    "objectID": "index.html#limitaciones",
    "href": "index.html#limitaciones",
    "title": "Análisis de datos",
    "section": "Limitaciones",
    "text": "Limitaciones\nUna de las limitaciones de esta metodología es que bertopic asigna cada documento a un solo cluster y, por tanto, a un solo tópico, lo cual podría no capturar la complejidad del texto.\nOtro aspecto a tomar en cuenta es que el algoritmo es susceptible a la elección de sus parámetros y el preprocesamiento de los datos, lo cual repercute directamente en los resultados. Debido a esto, se han expuesto todos los procedimientos aplicados.\nPor otro lado, la selección de tópicos está sujeta a interpretaciones, de ahí que se hayan establecido términos a partir de los cuales catalogarlos. A pesar de la selección, estos tópicos pueden contener palabras que no estén asociadas a temas de género o que dependan del contexto, por ello solo se trata de una estimación.\nPor último, un tema a considerar es que este tipo de modelado de tópicos con deep learning, requiere considerables recursos computacionales en caso de que se quiera replicar este anális.\n\nJupyter Notebooks creados por Fernanda Aguirre"
  },
  {
    "objectID": "pages/nikolas_dm.html",
    "href": "pages/nikolas_dm.html",
    "title": "Análisis de tweets de @nikolas_dm",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2012-08-14 23:32:27-03:00 / 2023-03-21 12:03:54-03:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 7035 entries, 3582 to 10616\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                            \n---  ------                   --------------  -----                            \n 0   query                    7035 non-null   object                           \n 1   id                       7035 non-null   float64                          \n 2   timestamp_utc            7035 non-null   int64                            \n 3   local_time               7035 non-null   object                           \n 4   user_screen_name         7035 non-null   object                           \n 5   text                     7035 non-null   object                           \n 6   possibly_sensitive       1841 non-null   object                           \n 7   retweet_count            7035 non-null   float64                          \n 8   like_count               7035 non-null   float64                          \n 9   reply_count              7035 non-null   float64                          \n 10  impression_count         266 non-null    object                           \n 11  lang                     7035 non-null   object                           \n 12  to_username              2197 non-null   object                           \n 13  to_userid                2197 non-null   float64                          \n 14  to_tweetid               2168 non-null   float64                          \n 15  source_name              7035 non-null   object                           \n 16  source_url               7035 non-null   object                           \n 17  user_location            7035 non-null   object                           \n 18  lat                      0 non-null      object                           \n 19  lng                      0 non-null      object                           \n 20  user_id                  7035 non-null   object                           \n 21  user_name                7035 non-null   object                           \n 22  user_verified            7035 non-null   float64                          \n 23  user_description         7035 non-null   object                           \n 24  user_url                 7035 non-null   object                           \n 25  user_image               7035 non-null   object                           \n 26  user_tweets              7035 non-null   object                           \n 27  user_followers           7035 non-null   float64                          \n 28  user_friends             7035 non-null   object                           \n 29  user_likes               7035 non-null   float64                          \n 30  user_lists               7035 non-null   float64                          \n 31  user_created_at          7035 non-null   object                           \n 32  user_timestamp_utc       7035 non-null   float64                          \n 33  collected_via            7035 non-null   object                           \n 34  match_query              7035 non-null   float64                          \n 35  retweeted_id             0 non-null      float64                          \n 36  retweeted_user           0 non-null      float64                          \n 37  retweeted_user_id        0 non-null      float64                          \n 38  retweeted_timestamp_utc  0 non-null      object                           \n 39  quoted_id                131 non-null    object                           \n 40  quoted_user              131 non-null    object                           \n 41  quoted_user_id           131 non-null    float64                          \n 42  quoted_timestamp_utc     131 non-null    float64                          \n 43  collection_time          7035 non-null   object                           \n 44  url                      7035 non-null   object                           \n 45  place_country_code       25 non-null     object                           \n 46  place_name               25 non-null     object                           \n 47  place_type               25 non-null     object                           \n 48  place_coordinates        25 non-null     object                           \n 49  links                    372 non-null    object                           \n 50  domains                  372 non-null    object                           \n 51  media_urls               1630 non-null   object                           \n 52  media_files              1630 non-null   object                           \n 53  media_types              1630 non-null   object                           \n 54  media_alt_texts          75 non-null     object                           \n 55  mentioned_names          2966 non-null   object                           \n 56  mentioned_ids            2567 non-null   object                           \n 57  hashtags                 166 non-null    object                           \n 58  intervention_type        0 non-null      float64                          \n 59  intervention_text        0 non-null      float64                          \n 60  intervention_url         0 non-null      float64                          \n 61  country                  7035 non-null   object                           \n 62  date                     7035 non-null   datetime64[ns, America/Sao_Paulo]\ndtypes: datetime64[ns, America/Sao_Paulo](1), float64(20), int64(1), object(41)\nmemory usage: 3.4+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\nyoutu.be                       96\ntwcm.me                        56\nask.fm                         24\nyoutube.com                    18\notempo.com.br                  16\ngoogle.com.br                  13\nmoi.st                         11\nt.me                           10\ninstagram.com                   6\njornaldacidadeonline.com.br     6\nbit.ly                          6\n24.media.tumblr.com             5\nem.com.br                       5\nitatiaia.com.br                 5\ng1.globo.com                    5\nveja.abril.com.br               4\nbrasilsemmedo.com               4\n25.media.tumblr.com             4\nphelipe.com.br                  4\nlivrariadonikolas.com           4\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\n28000                       17\nvirabrasil                  12\nptnuncamais                  7\nforakalil                    6\nb28                          5\nreagebh                      5\nforamaia                     4\ndevolveodinheirojanones      4\ngobolsonaromundial           3\nmpnofelipeneto               3\nbh                           3\nbelohorizonte                3\nderretefelipeneto            3\nfamiliascontrafelipeneto     3\npaz                          3\nbolsonaro2022                3\ng1                           3\nfechadocombolsonaro          3\ndeixaopovotrabalhar          2\nnikolasnopânico              2\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\njairbolsonaro      208\nfelipeneto         143\n_portiinho         104\namanddok            99\nbrunoenglerdm       77\nbolsonarosp         61\nlorena_rcp          59\nanamarciaac         56\nlulaoficial         54\nclaramurta          52\ntaoquei1            51\nalexandrekalil      47\ndanilogentili       43\nandrejanonesadv     40\nanaclara_ah         39\ndededumontt         37\nbrendiinhasc        36\nnikolas_dm          35\nbuenoosophia        34\nfernandarian        33\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Portuguese\nnlp = spacy.load(\"pt_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\npra           1013\nbh             338\nbrasil         236\nbolsonaro      234\nlula           220\ndia            213\nesquerda       206\nhoje           196\ntá             194\ngente          181\nnao            177\npessoas        163\npresidente     150\ncara           149\nkalil          145\ndeus           138\nvei            126\npro            125\nmundo          122\nverdade        116\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n21    623\n19    592\n20    533\n18    524\n14    504\n13    488\n22    484\n12    469\n17    463\n16    406\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for iPhone        5013\nTwitter Web Client        1487\nTwitter Web App            283\nTwitter for Android        183\nTwitcom - Comunidades       58\nTwitCasting                 11\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con el 20% del total de tópicos generados\n\n\nCode\n# calculate the 20% from the total of topics\nnum_topics = len(topic_model.get_topic_info())\nper_topics = int(num_topics * 20 / 100)\n\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=per_topics)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=per_topics)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [14]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @nikolas_dm, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 7035 tweets de @nikolas_dm, alrededor de 222 hablan sobre temas de género, es decir, cerca del 3.16%\nLista de palabras en tópicos [14]:\n['mulher', 'aborto', 'feminista', 'feminismo', 'feministas', 'mulheres', 'movimento', 'chega', 'homem', 'chifre']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/familiaecuador.html",
    "href": "pages/familiaecuador.html",
    "title": "Análisis de tweets de @_FamiliaEcuador",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2018-07-28 18:41:21-05:00 / 2023-03-20 11:57:01-05:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 2716 entries, 196700 to 199415\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                            \n---  ------                   --------------  -----                            \n 0   query                    2716 non-null   object                           \n 1   id                       2716 non-null   float64                          \n 2   timestamp_utc            2716 non-null   int64                            \n 3   local_time               2716 non-null   object                           \n 4   user_screen_name         2716 non-null   object                           \n 5   text                     2716 non-null   object                           \n 6   possibly_sensitive       1663 non-null   object                           \n 7   retweet_count            2716 non-null   float64                          \n 8   like_count               2716 non-null   float64                          \n 9   reply_count              2716 non-null   float64                          \n 10  impression_count         46 non-null     object                           \n 11  lang                     2716 non-null   object                           \n 12  to_username              1199 non-null   object                           \n 13  to_userid                1199 non-null   float64                          \n 14  to_tweetid               1187 non-null   float64                          \n 15  source_name              2716 non-null   object                           \n 16  source_url               2716 non-null   object                           \n 17  user_location            2716 non-null   object                           \n 18  lat                      0 non-null      object                           \n 19  lng                      0 non-null      object                           \n 20  user_id                  2716 non-null   object                           \n 21  user_name                2716 non-null   object                           \n 22  user_verified            2716 non-null   float64                          \n 23  user_description         2716 non-null   object                           \n 24  user_url                 2716 non-null   object                           \n 25  user_image               2716 non-null   object                           \n 26  user_tweets              2716 non-null   object                           \n 27  user_followers           2716 non-null   float64                          \n 28  user_friends             2716 non-null   object                           \n 29  user_likes               2716 non-null   float64                          \n 30  user_lists               2716 non-null   float64                          \n 31  user_created_at          2716 non-null   object                           \n 32  user_timestamp_utc       2716 non-null   float64                          \n 33  collected_via            2716 non-null   object                           \n 34  match_query              2716 non-null   float64                          \n 35  retweeted_id             0 non-null      float64                          \n 36  retweeted_user           0 non-null      float64                          \n 37  retweeted_user_id        0 non-null      float64                          \n 38  retweeted_timestamp_utc  0 non-null      object                           \n 39  quoted_id                412 non-null    object                           \n 40  quoted_user              412 non-null    object                           \n 41  quoted_user_id           412 non-null    float64                          \n 42  quoted_timestamp_utc     412 non-null    float64                          \n 43  collection_time          2716 non-null   object                           \n 44  url                      2716 non-null   object                           \n 45  place_country_code       31 non-null     object                           \n 46  place_name               31 non-null     object                           \n 47  place_type               31 non-null     object                           \n 48  place_coordinates        31 non-null     object                           \n 49  links                    478 non-null    object                           \n 50  domains                  478 non-null    object                           \n 51  media_urls               1644 non-null   object                           \n 52  media_files              1644 non-null   object                           \n 53  media_types              1644 non-null   object                           \n 54  media_alt_texts          239 non-null    object                           \n 55  mentioned_names          1946 non-null   object                           \n 56  mentioned_ids            1904 non-null   object                           \n 57  hashtags                 1630 non-null   object                           \n 58  intervention_type        0 non-null      float64                          \n 59  intervention_text        0 non-null      float64                          \n 60  intervention_url         0 non-null      float64                          \n 61  country                  2716 non-null   object                           \n 62  date                     2716 non-null   datetime64[ns, America/Guayaquil]\ndtypes: datetime64[ns, America/Guayaquil](1), float64(20), int64(1), object(41)\nmemory usage: 1.3+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\nyoutu.be                           63\nbit.ly                             43\nfacebook.com                       30\ninstagram.com                      25\nyoutube.com                        19\naciprensa.com                      19\neluniverso.com                     18\necuadorporlafamilia.org            14\narquidiocesisdeguayaquil.org.ec    11\ncitizengo.org                      11\nfamiliaecuador.org                 10\ntwitter.com                         9\nopen.spotify.com                    8\nliveaction.org                      6\nfoxnews.com                         6\nexpreso.ec                          5\npscp.tv                             5\nbuff.ly                             5\ndrive.google.com                    5\nforms.gle                           4\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\necuadoresprovida           307\nsalvemoslas2vidas          242\necuador                    176\nprovida                    118\nescudero                    89\nabortoporviolacion          78\necuadorporlafamilia         70\naborto                      63\ncoip                        58\nasambleistaqueserespeta     57\nleyabortistano              56\nmarthavillafuerte           46\nescudera                    44\nvotoprovida2021             42\nescuderos                   40\nconabortonotevoto           37\nprolife                     36\nchantajehumanitario         35\nmentirasverdes              29\njuntosporlafamilia          29\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nasambleaecuador    332\nhectoryepezm       145\njusticiaan         134\netorrescobo        132\nlenin              120\nlourdescuestao     105\namishijoseduco      88\nagustinlaje         77\namparo_medina       71\necuadorprovida      71\ncesarrohon          61\nlacristifranco      57\njulietasagnay       51\ngomezrobertoa       51\neluniversocom       49\nmarthaceciliavl     47\ncrisvalverdej       46\npolyugarteg         44\nviviana_bonilla     41\ncorteconstecu       38\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvida                562\naborto              378\nfamilia             354\necuadoresprovida    316\ngracias             305\necuador             299\nprovida             218\napoyo               152\nmujeres             139\nviolación           131\nniños               120\nnacer               119\nhijos               119\nconcepción          118\ncausa               116\nley                 115\nmujer               112\nescudero            112\nthe                 108\nvoz                 108\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n12    206\n15    193\n09    183\n08    175\n10    175\n16    173\n13    172\n11    168\n14    156\n17    149\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for Android    2398\nTwitter Web App         151\nTwitter Web Client      120\nTwitter for iPhone       17\nInstagram                17\nTweetDeck                13\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=41)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [4, 40]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @_FamiliaEcuador, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 2716 tweets de @_FamiliaEcuador, alrededor de 1638 hablan sobre temas de género, es decir, cerca del 60.31%\nLista de palabras en tópicos [4, 40]:\n['aborto', 'ecuador', 'abortista', 'violación', 'vida', 'derechos', 'nacer', 'argentina', 'méxico', 'ley', 'niabusoniaborto', 'mentirasverdes', 'abortoporviolacion', 'berreado', 'prestos', 'gkecuador', 'entrevista', 'confundir', 'hipocresiaverde', 'simposio']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/unidosxlavidaco.html",
    "href": "pages/unidosxlavidaco.html",
    "title": "Análisis de tweets de @UnidosxlaVidaCo",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2011-06-14 20:50:03-05:00 / 2023-03-01 12:22:56-05:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 7830 entries, 171420 to 179249\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                         \n---  ------                   --------------  -----                         \n 0   query                    7830 non-null   object                        \n 1   id                       7830 non-null   float64                       \n 2   timestamp_utc            7830 non-null   int64                         \n 3   local_time               7830 non-null   object                        \n 4   user_screen_name         7830 non-null   object                        \n 5   text                     7830 non-null   object                        \n 6   possibly_sensitive       4135 non-null   object                        \n 7   retweet_count            7830 non-null   float64                       \n 8   like_count               7830 non-null   float64                       \n 9   reply_count              7830 non-null   float64                       \n 10  impression_count         16 non-null     object                        \n 11  lang                     7830 non-null   object                        \n 12  to_username              1568 non-null   object                        \n 13  to_userid                1568 non-null   float64                       \n 14  to_tweetid               1281 non-null   float64                       \n 15  source_name              7830 non-null   object                        \n 16  source_url               7830 non-null   object                        \n 17  user_location            7830 non-null   object                        \n 18  lat                      4 non-null      object                        \n 19  lng                      4 non-null      object                        \n 20  user_id                  7830 non-null   object                        \n 21  user_name                7830 non-null   object                        \n 22  user_verified            7830 non-null   float64                       \n 23  user_description         7830 non-null   object                        \n 24  user_url                 7830 non-null   object                        \n 25  user_image               7830 non-null   object                        \n 26  user_tweets              7830 non-null   object                        \n 27  user_followers           7830 non-null   float64                       \n 28  user_friends             7830 non-null   object                        \n 29  user_likes               7830 non-null   float64                       \n 30  user_lists               7830 non-null   float64                       \n 31  user_created_at          7830 non-null   object                        \n 32  user_timestamp_utc       7830 non-null   float64                       \n 33  collected_via            7830 non-null   object                        \n 34  match_query              7830 non-null   float64                       \n 35  retweeted_id             0 non-null      float64                       \n 36  retweeted_user           0 non-null      float64                       \n 37  retweeted_user_id        0 non-null      float64                       \n 38  retweeted_timestamp_utc  0 non-null      object                        \n 39  quoted_id                293 non-null    object                        \n 40  quoted_user              293 non-null    object                        \n 41  quoted_user_id           293 non-null    float64                       \n 42  quoted_timestamp_utc     293 non-null    float64                       \n 43  collection_time          7830 non-null   object                        \n 44  url                      7830 non-null   object                        \n 45  place_country_code       265 non-null    object                        \n 46  place_name               265 non-null    object                        \n 47  place_type               265 non-null    object                        \n 48  place_coordinates        265 non-null    object                        \n 49  links                    2904 non-null   object                        \n 50  domains                  2904 non-null   object                        \n 51  media_urls               1533 non-null   object                        \n 52  media_files              1533 non-null   object                        \n 53  media_types              1533 non-null   object                        \n 54  media_alt_texts          47 non-null     object                        \n 55  mentioned_names          2767 non-null   object                        \n 56  mentioned_ids            2613 non-null   object                        \n 57  hashtags                 4969 non-null   object                        \n 58  intervention_type        0 non-null      float64                       \n 59  intervention_text        0 non-null      float64                       \n 60  intervention_url         0 non-null      float64                       \n 61  country                  7830 non-null   object                        \n 62  date                     7830 non-null   datetime64[ns, America/Bogota]\ndtypes: datetime64[ns, America/Bogota](1), float64(20), int64(1), object(41)\nmemory usage: 3.8+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains.nlargest(20)\n\ntop_domains\n\n\ndomains\nfb.me                     1231\nbit.ly                     242\nunidosporlavida.com        193\nfacebook.com               171\ninstagram.com              125\nsumall.com                  98\nyoutube.com                 68\nlifenews.com                40\ncitizengo.org               36\nyoutu.be                    33\n20ft.net                    33\naciprensa.com               19\nvotocatolico.co             18\nactuall.com                 15\nshar.es                     15\nliveactionnews.org          15\ntwitter.com                 12\nes.gaudiumpress.org         12\nreligionenlibertad.com      10\nrazonmasfe.com               8\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\nsialavida                647\naborto                   416\n9marchaxlavida           373\nnoalaborto               325\ncolombiaesprovida        295\neutanasia                157\nprocuradorordóñez        139\nsialprocurador           138\nyosoyprovida             135\nsoyprovida               108\nnegocio                  106\nrepost                   100\ntodavidaimporta          100\nelijolas2vidas            98\ncolombia                  93\neutanasiano               91\nabortocero                91\nfiestaxlavida             91\n4mayo7marchaporlavida     89\ncaravanaporlavida         88\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nmarceposada        196\ncolombiaprovida    194\ncconstitucional    176\nmonicaroa          173\nsialprocurador     106\nunidosxlavidaco    105\nnoticiasrcn         83\n7marcofidelr        62\namadarosa           59\nreferendoxvida      51\ncolombiaderecha     49\nprofamiliacol       48\noea_oficial         47\ncomisionprimera     42\ncamaracolombia      40\nlam_vero            36\nwradiocolombia      35\nunidosxlavida       35\nyosoyprovida        34\naciprensa           32\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Número de likes en el tiempo',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvida                 2070\naborto               1097\ncolombia              719\nsialavida             661\ncolombiaesprovida     437\nmayo                  390\nq                     388\nnoalaborto            370\neutanasia             323\nderecho               323\ngracias               309\nprovida               308\nmuerte                268\nfeliz                 268\nd                     263\nvoz                   250\nmujer                 222\nfamilia               210\nmujeres               204\nconcepción            191\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n11    786\n10    737\n12    677\n09    622\n14    525\n13    519\n08    519\n07    448\n19    426\n15    403\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for iPhone             2031\nTwitter Web App                1706\nTwitter Web Client             1487\nFacebook                       1468\nTwitter for Android             412\nMobile Web                      163\nTweetDeck                       133\nerased88075                     131\nTwitter for Websites            124\nInstagram                        99\nUberSocial for iPhone            22\nMobile Web (M2)                  12\niOS                              11\nTwitter for Android Tablets      10\nTwitter for Mac                   7\nTweeet! on iOS                    4\nHootsuite Inc.                    3\nBuffer                            3\nHootsuite                         2\nTwibbon                           1\nPeriscope                         1\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con el 20% del total de tópicos generados\n\n\nCode\n# calculate the 20% from the total of topics\nnum_topics = len(topic_model.get_topic_info())\nper_topics = int(num_topics * 20 / 100)\n\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=per_topics)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=per_topics)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [1]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @UnidosxlaVidaCo, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 7830 tweets de @UnidosxlaVidaCo, alrededor de 2750 hablan sobre temas de género, es decir, cerca del 35.12%\nLista de palabras en tópicos [1]:\n['aborto', 'negocio', 'eutanasia', 'abortocero', 'mujeres', 'mujer', 'sialavida', 'abortonoesderecho', 'parenthood', 'apoyo']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/mamelafialloflo.html",
    "href": "pages/mamelafialloflo.html",
    "title": "Análisis de tweets de @MamelaFialloFlo",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2013-08-20 15:43:12-05:00 / 2023-03-21 08:54:01-05:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 23687 entries, 21498 to 45184\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                            \n---  ------                   --------------  -----                            \n 0   query                    23687 non-null  object                           \n 1   id                       23687 non-null  float64                          \n 2   timestamp_utc            23687 non-null  int64                            \n 3   local_time               23687 non-null  object                           \n 4   user_screen_name         23687 non-null  object                           \n 5   text                     23687 non-null  object                           \n 6   possibly_sensitive       4337 non-null   object                           \n 7   retweet_count            23687 non-null  float64                          \n 8   like_count               23687 non-null  float64                          \n 9   reply_count              23687 non-null  float64                          \n 10  impression_count         1985 non-null   object                           \n 11  lang                     23687 non-null  object                           \n 12  to_username              16705 non-null  object                           \n 13  to_userid                16705 non-null  float64                          \n 14  to_tweetid               16687 non-null  float64                          \n 15  source_name              23687 non-null  object                           \n 16  source_url               23687 non-null  object                           \n 17  user_location            0 non-null      object                           \n 18  lat                      0 non-null      object                           \n 19  lng                      0 non-null      object                           \n 20  user_id                  23687 non-null  object                           \n 21  user_name                23687 non-null  object                           \n 22  user_verified            23687 non-null  float64                          \n 23  user_description         23687 non-null  object                           \n 24  user_url                 0 non-null      object                           \n 25  user_image               23687 non-null  object                           \n 26  user_tweets              23687 non-null  object                           \n 27  user_followers           23687 non-null  float64                          \n 28  user_friends             23687 non-null  object                           \n 29  user_likes               23687 non-null  float64                          \n 30  user_lists               23687 non-null  float64                          \n 31  user_created_at          23687 non-null  object                           \n 32  user_timestamp_utc       23687 non-null  float64                          \n 33  collected_via            23687 non-null  object                           \n 34  match_query              23687 non-null  float64                          \n 35  retweeted_id             0 non-null      float64                          \n 36  retweeted_user           0 non-null      float64                          \n 37  retweeted_user_id        0 non-null      float64                          \n 38  retweeted_timestamp_utc  0 non-null      object                           \n 39  quoted_id                2119 non-null   object                           \n 40  quoted_user              2119 non-null   object                           \n 41  quoted_user_id           2119 non-null   float64                          \n 42  quoted_timestamp_utc     2119 non-null   float64                          \n 43  collection_time          23687 non-null  object                           \n 44  url                      23687 non-null  object                           \n 45  place_country_code       58 non-null     object                           \n 46  place_name               58 non-null     object                           \n 47  place_type               58 non-null     object                           \n 48  place_coordinates        58 non-null     object                           \n 49  links                    1626 non-null   object                           \n 50  domains                  1626 non-null   object                           \n 51  media_urls               3806 non-null   object                           \n 52  media_files              3806 non-null   object                           \n 53  media_types              3806 non-null   object                           \n 54  media_alt_texts          361 non-null    object                           \n 55  mentioned_names          17305 non-null  object                           \n 56  mentioned_ids            16211 non-null  object                           \n 57  hashtags                 2499 non-null   object                           \n 58  intervention_type        0 non-null      float64                          \n 59  intervention_text        0 non-null      float64                          \n 60  intervention_url         0 non-null      float64                          \n 61  country                  23687 non-null  object                           \n 62  date                     23687 non-null  datetime64[ns, America/Guayaquil]\ndtypes: datetime64[ns, America/Guayaquil](1), float64(20), int64(1), object(41)\nmemory usage: 11.6+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains.nlargest(20)\n\ntop_domains\n\n\ndomains\npanampost.com                321\nes.panampost.com             165\nyoutube.com                  105\nyoutu.be                      85\ntwitter.com                   52\nbit.ly                        43\ninstagram.com                 37\ngaceta.es                     32\nfacebook.com                  21\nbuff.ly                       20\npublichealth.lacounty.gov     19\neluniverso.com                18\namazon.com                    14\nabc.es                        13\nlozierinstitute.org           13\nvatican.va                    10\namp.milenio.com                9\nlifenews.com                   9\nlibrary.brown.edu              9\nbbc.com                        9\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\nleyabortistano              243\nfemeninasífeministano        87\ncoronavirus                  87\nsalvemoslasdosvidas          64\nblacklivesmatter             64\necuadoresprovida             47\nvetopresidencial             42\ntiraníasanitaria             41\nprovida                      33\nleydelviolador               29\nsíalavida                    28\nnoalaborto                   27\nnohablesenminombre           26\nabortolegal                  26\nguateesvida                  24\ndatomatarelato               24\nlaviolencianotienegénero     23\ncovid19                      22\n8m                           21\njusticiaporlucio             19\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nagustinlaje        330\nlassoguillermo     324\nmamelafialloflo    271\npanampost_es       239\njairbolsonaro      210\netorrescobo        203\nfelipeleon88       177\nrealdonaldtrump    171\nxileone            138\npjavieror          135\nvox_es             131\nasambleaecuador    129\nsimpliciterpaco    127\nfundlibre          118\npmunoziturrieta    110\ngloriaalvarez85    109\nfreityt            109\njmilei              98\navelinaponceg       97\npontifex_es         95\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Número de likes en el tiempo',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\ngracias       2344\nmujer         1729\nvida          1548\nmujeres       1394\naborto        1381\nfeminismo     1167\nlibertad       924\nmatar          881\nderecho        701\nthe            666\necuador        657\nhombre         630\nquieren        617\nfeministas     614\nizquierda      603\nmadre          586\npersonas       549\ndios           529\nviolencia      528\nhombres        528\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n08    1665\n09    1659\n10    1573\n22    1571\n07    1522\n11    1338\n23    1312\n21    1302\n19    1268\n12    1237\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for iPhone     16202\nTwitter Web App         7273\nTwitter Web Client       165\nTwitter for Android       47\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con el 20% del total de tópicos generados\n\n\nCode\n# calculate the 20% from the total of topics\nnum_topics = len(topic_model.get_topic_info())\nper_topics = int(num_topics * 20 / 100)\n\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=per_topics)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=per_topics)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [1, 5]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @MamelaFialloFlo, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 23687 tweets de @MamelaFialloFlo, alrededor de 9016 hablan sobre temas de género, es decir, cerca del 38.06%\nLista de palabras en tópicos [1, 5]:\n['feminismo', 'mujer', 'mujeres', 'feministas', 'feminista', 'hombres', 'violencia', 'hombre', 'lgbt', 'trans', 'aborto', 'pro', 'mujeres', 'provida', 'feministas', 'abortos', 'abortar', 'matar', 'leyabortistano', 'vida']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/misionpaz.html",
    "href": "pages/misionpaz.html",
    "title": "Análisis de tweets de @misionpaz_",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2010-02-06 20:50:46-05:00 / 2023-03-21 05:00:25-05:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 17450 entries, 179250 to 196699\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                         \n---  ------                   --------------  -----                         \n 0   query                    17450 non-null  object                        \n 1   id                       17450 non-null  float64                       \n 2   timestamp_utc            17450 non-null  int64                         \n 3   local_time               17450 non-null  object                        \n 4   user_screen_name         17450 non-null  object                        \n 5   text                     17450 non-null  object                        \n 6   possibly_sensitive       15102 non-null  object                        \n 7   retweet_count            17450 non-null  float64                       \n 8   like_count               17450 non-null  float64                       \n 9   reply_count              17450 non-null  float64                       \n 10  impression_count         620 non-null    object                        \n 11  lang                     17450 non-null  object                        \n 12  to_username              100 non-null    object                        \n 13  to_userid                100 non-null    float64                       \n 14  to_tweetid               87 non-null     float64                       \n 15  source_name              17450 non-null  object                        \n 16  source_url               17450 non-null  object                        \n 17  user_location            17450 non-null  object                        \n 18  lat                      9 non-null      object                        \n 19  lng                      9 non-null      object                        \n 20  user_id                  17450 non-null  object                        \n 21  user_name                17450 non-null  object                        \n 22  user_verified            17450 non-null  float64                       \n 23  user_description         17450 non-null  object                        \n 24  user_url                 17450 non-null  object                        \n 25  user_image               17450 non-null  object                        \n 26  user_tweets              17450 non-null  object                        \n 27  user_followers           17450 non-null  float64                       \n 28  user_friends             17450 non-null  object                        \n 29  user_likes               17450 non-null  float64                       \n 30  user_lists               17450 non-null  float64                       \n 31  user_created_at          17450 non-null  object                        \n 32  user_timestamp_utc       17450 non-null  float64                       \n 33  collected_via            17450 non-null  object                        \n 34  match_query              17450 non-null  float64                       \n 35  retweeted_id             0 non-null      float64                       \n 36  retweeted_user           0 non-null      float64                       \n 37  retweeted_user_id        0 non-null      float64                       \n 38  retweeted_timestamp_utc  0 non-null      object                        \n 39  quoted_id                51 non-null     object                        \n 40  quoted_user              51 non-null     object                        \n 41  quoted_user_id           51 non-null     float64                       \n 42  quoted_timestamp_utc     51 non-null     float64                       \n 43  collection_time          17450 non-null  object                        \n 44  url                      17450 non-null  object                        \n 45  place_country_code       795 non-null    object                        \n 46  place_name               795 non-null    object                        \n 47  place_type               795 non-null    object                        \n 48  place_coordinates        795 non-null    object                        \n 49  links                    10194 non-null  object                        \n 50  domains                  10194 non-null  object                        \n 51  media_urls               7526 non-null   object                        \n 52  media_files              7526 non-null   object                        \n 53  media_types              7526 non-null   object                        \n 54  media_alt_texts          1940 non-null   object                        \n 55  mentioned_names          3066 non-null   object                        \n 56  mentioned_ids            2583 non-null   object                        \n 57  hashtags                 10072 non-null  object                        \n 58  intervention_type        0 non-null      float64                       \n 59  intervention_text        0 non-null      float64                       \n 60  intervention_url         0 non-null      float64                       \n 61  country                  17450 non-null  object                        \n 62  date                     17450 non-null  datetime64[ns, America/Bogota]\ndtypes: datetime64[ns, America/Bogota](1), float64(20), int64(1), object(41)\nmemory usage: 8.5+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\nfb.me                                  3803\ninstagram.com                          1778\nyoutu.be                               1280\now.ly                                  1173\nmisionpaz.org                           624\ntwitter.com                             216\nyoutube.com                             176\nfb.me|ow.ly                             150\nmisionpaz.org|youtu.be                  135\nbit.ly                                   98\npst.cr                                   90\njhonmilton.org                           64\npscp.tv                                  58\nfb.me|youtube.com                        58\nexplosion.misionpaz.org                  56\ninscripciones.genesis.misionpaz.org      38\nwp.me                                    37\ncongresos.misionpaz.org                  23\nmisiónpaz.org                            19\nfb.me|new.livestream.com                 18\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\nmisionpazmicasa           1561\nmisionpaz                 1098\nmpntucasa                 1012\niglesiampn                 887\ndevocional                 881\nmisionpazencasa            604\nfeparagrandesvictorias     514\n20añostransformando        333\nesnuestracasa              327\nenvivo                     320\nmpnenvivo                  278\nfamiliampn                 253\nsomosfamilia               245\nyosoympn                   240\nmpnnuestracasa             236\nexplosioncontundente       220\navivamiento                185\nfiestademilagros           179\nvive                       176\nmpn                        157\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\njohnmiltonr_          712\ngerarydiana           342\njhonmiltonr           270\njoelmanderfield       257\nyoutube               186\nprjhonmilton          171\nce_palace             164\ngissymander           151\nprofetanormasr        117\nmisionpaziglesia       76\nmisionpaz_             75\nsoynormaruiz           45\nmarcobarrientos        45\nnormanormaruiz         41\nfundacionmisionpaz     30\nprgerardoydiana        28\npastorcashluna         25\ncesarfajardosm         24\notonielfont            23\nevancraft              21\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\ndios               6122\npaz                2051\nmisión             1780\nvida               1589\nmisionpazmicasa    1556\nmensaje            1280\ncompleto           1193\ntiempo             1123\nmisionpaz          1100\nconéctate          1086\ndevocional         1033\nmpntucasa          1016\namor               1000\ncelebración         983\nfamilia             926\niglesiampn          891\njesús               851\npm                  809\nesperamos           805\nseñor               793\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n18    1245\n20    1223\n19    1119\n04    1063\n12    1058\n11    1041\n09    1039\n17    1027\n08    1003\n10     996\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nFacebook                    4460\nTwitter Web App             2791\nHootsuite                   2423\nInstagram                   1614\nTwitter Web Client          1341\nPostcron App                 971\nTwitter for iPad             868\nTwitter for Android          682\nTwitter for iPhone           627\nTweetDeck                    290\nSocialGest                   285\nGoogle                       254\nTwitter Media Studio         230\nRepost.social                167\nHootsuite Inc.               165\na Ning Network               106\nRestream.io                   72\nPeriscope                     57\nerased9_3Ud7cuBk0y            39\nerased132190                   3\nUstream.TV                     2\nLinkedIn                       1\nTwitter for Advertisers.       1\nerased138961                   1\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con el 20% del total de tópicos generados\n\n\nCode\n# calculate the 20% from the total of topics\nnum_topics = len(topic_model.get_topic_info())\nper_topics = int(num_topics * 20 / 100)\n\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=per_topics)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=per_topics)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nNo se identificó ningún tópico que hable de manera contundente sobre aborto, feminismo y genero\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/politicos.html",
    "href": "pages/politicos.html",
    "title": "Análisis de tweets de @MariaFdaCabal, @etorrescobo y @nikolas_dm",
    "section": "",
    "text": "Code\n# filter data\necu = data[data['user_screen_name'] == 'etorrescobo']\n\n# convert time column to Brasilia, Brazil timezone\necu['date'] = ecu['date'].dt.tz_convert(pytz.timezone('America/Guayaquil'))\n\n# filter data\nbra = data[data['user_screen_name'] == 'nikolas_dm']\n\n# convert time column to Brasilia, Brazil timezone\nbra['date'] = bra['date'].dt.tz_convert(pytz.timezone('America/Sao_Paulo'))\n\n# filter data\ncol = data[data['user_screen_name'] == 'MariaFdaCabal']\n\n# convert time column to Brasilia, Brazil timezone\ncol['date'] = col['date'].dt.tz_convert(pytz.timezone('America/Bogota'))\n\n# concatenate dataframess\ndf = pd.concat([ecu, col, bra], axis=0)\n\nprint(len(df))\n\n\n47811\n\n\n\nPre-procesamiento de texto es español\n\n\nCode\n# load the spacy model for Spanish\nnlp_es = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS_ES = nlp_es.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp_es(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS_ES and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ncol['text_pre'] = col['text'].apply(filter_stopwords)\necu['text_pre'] = ecu['text'].apply(filter_stopwords)\n\n\n\n\nPre-procesamiento de texto en portugués\n\n\nCode\n# load the spacy model for Portuguese\nnlp_pt = spacy.load(\"pt_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS_PT = nlp_pt.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp_pt(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS_PT and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\nbra['text_pre'] = bra['text'].apply(filter_stopwords)\n\n\n\n\nTópicos en tweets de @MariaFdaCabal\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ncol['text_pre'] = col['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ncol['text_pre'] = col['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = col['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n                                                \n\n\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=31)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=31)\n\n\n\n                                                \n\n\n\n\nCode\n# selection of topics\ntopics = [13]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_col = col[col['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_col) / len(col), 2)\nprint(f\"Del total de {len(col)} tweets de @MariaFdaCabal, alrededor de {len(filtered_col)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 32462 tweets de @MariaFdaCabal, alrededor de 753 hablan sobre temas de género, es decir, cerca del 2.32%\nLista de palabras en tópicos [13]:\n['madrid', 'real', 'hala', 'barcelona', 'macron', 'vs', 'copa', 'europeos', 'francia', 'atlético']\n\n\n\n\nTópicos en tweets de @etorrescobo\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\necu['text_pre'] = ecu['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\necu['text_pre'] = ecu['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = ecu['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=31)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=31)\n\n\n\n                                                \n\n\n\n\nCode\n# selection of topics\ntopics = [6]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_ecu = ecu[ecu['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_ecu) / len(ecu), 2)\nprint(f\"Del total de {len(ecu)} tweets de @etorrescobo, alrededor de {len(filtered_ecu)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 8314 tweets de @etorrescobo, alrededor de 423 hablan sobre temas de género, es decir, cerca del 5.09%\nLista de palabras en tópicos [6]:\n['aborto', 'niños', 'mujeres', 'violación', 'adolescentes', 'feminismo', 'despenalización', 'mujer', 'hijos', 'vida']\n\n\n\n\nTópicos en tweets de @nikolas_dm\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\nbra['text_pre'] = bra['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\nbra['text_pre'] = bra['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = bra['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=31)\n\ntopic_model.visualize_barchart(top_n_topics=31)\n\n\n\n                                                \n\n\n\n\nCode\n# selection of topics\ntopics = [12]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_bra = bra[bra['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_bra) / len(bra), 2)\nprint(f\"Del total de {len(bra)} tweets de @nikolas_dm, alrededor de {len(filtered_bra)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 7035 tweets de @nikolas_dm, alrededor de 222 hablan sobre temas de género, es decir, cerca del 3.16%\nLista de palabras en tópicos [12]:\n['mulher', 'aborto', 'feminista', 'feminismo', 'feministas', 'mulheres', 'movimento', 'chega', 'homem', 'geralmente']\n\n\n\n\nVisualización\n\n\nCode\n# concatenate dataframess\nfiltered_df = pd.concat([filtered_col, filtered_ecu, filtered_bra], axis=0)\n\n# replace 'T' from column\nfiltered_df['date'] = filtered_df['local_time'].str.replace('T', ' ')\n\nfiltered_df['date'] = pd.to_datetime(filtered_df['date'], format='%Y-%m-%d %H:%M:%S')\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                #  size='impressions', \n                 color='user_name',\n                 labels={\"user_name\": \"Cuenta de Twitter\"},\n                 color_discrete_sequence=[\"#FD9432\", \"#5647E5\", \"#F666f8\"],\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Likes vs Retweets en tweets que hablan sobre temas de género',\n    xaxis_title='Número de likes',\n    yaxis_title='Número de retweets',\n    plot_bgcolor=\"#eef4f5\"\n)\n\nfig.show()"
  },
  {
    "objectID": "pages/mariafdacabal.html",
    "href": "pages/mariafdacabal.html",
    "title": "Análisis de tweets de @MariaFdaCabal",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos:\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2012-01-18 20:07:08-05:00 / 2023-03-21 09:59:39-05:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 32462 entries, 138957 to 171419\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                         \n---  ------                   --------------  -----                         \n 0   query                    32462 non-null  object                        \n 1   id                       32462 non-null  float64                       \n 2   timestamp_utc            32462 non-null  int64                         \n 3   local_time               32462 non-null  object                        \n 4   user_screen_name         32462 non-null  object                        \n 5   text                     32462 non-null  object                        \n 6   possibly_sensitive       15705 non-null  object                        \n 7   retweet_count            32461 non-null  float64                       \n 8   like_count               32461 non-null  float64                       \n 9   reply_count              32461 non-null  float64                       \n 10  impression_count         1206 non-null   object                        \n 11  lang                     32461 non-null  object                        \n 12  to_username              7757 non-null   object                        \n 13  to_userid                7757 non-null   float64                       \n 14  to_tweetid               7498 non-null   float64                       \n 15  source_name              32461 non-null  object                        \n 16  source_url               32461 non-null  object                        \n 17  user_location            32461 non-null  object                        \n 18  lat                      0 non-null      object                        \n 19  lng                      0 non-null      object                        \n 20  user_id                  32461 non-null  object                        \n 21  user_name                32461 non-null  object                        \n 22  user_verified            32461 non-null  float64                       \n 23  user_description         32461 non-null  object                        \n 24  user_url                 32461 non-null  object                        \n 25  user_image               32461 non-null  object                        \n 26  user_tweets              32461 non-null  object                        \n 27  user_followers           32461 non-null  float64                       \n 28  user_friends             32461 non-null  object                        \n 29  user_likes               32461 non-null  float64                       \n 30  user_lists               32461 non-null  float64                       \n 31  user_created_at          32461 non-null  object                        \n 32  user_timestamp_utc       32461 non-null  float64                       \n 33  collected_via            32461 non-null  object                        \n 34  match_query              32461 non-null  float64                       \n 35  retweeted_id             0 non-null      float64                       \n 36  retweeted_user           0 non-null      float64                       \n 37  retweeted_user_id        0 non-null      float64                       \n 38  retweeted_timestamp_utc  0 non-null      object                        \n 39  quoted_id                4421 non-null   object                        \n 40  quoted_user              4421 non-null   object                        \n 41  quoted_user_id           4421 non-null   float64                       \n 42  quoted_timestamp_utc     4421 non-null   float64                       \n 43  collection_time          32461 non-null  object                        \n 44  url                      32461 non-null  object                        \n 45  place_country_code       3 non-null      object                        \n 46  place_name               3 non-null      object                        \n 47  place_type               3 non-null      object                        \n 48  place_coordinates        3 non-null      object                        \n 49  links                    11585 non-null  object                        \n 50  domains                  11585 non-null  object                        \n 51  media_urls               7326 non-null   object                        \n 52  media_files              7326 non-null   object                        \n 53  media_types              7326 non-null   object                        \n 54  media_alt_texts          898 non-null    object                        \n 55  mentioned_names          14806 non-null  object                        \n 56  mentioned_ids            14239 non-null  object                        \n 57  hashtags                 6863 non-null   object                        \n 58  intervention_type        0 non-null      float64                       \n 59  intervention_text        0 non-null      float64                       \n 60  intervention_url         0 non-null      float64                       \n 61  country                  32461 non-null  object                        \n 62  date                     32462 non-null  datetime64[ns, America/Bogota]\ndtypes: datetime64[ns, America/Bogota](1), float64(20), int64(1), object(41)\nmemory usage: 15.9+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\nbit.ly                    1510\nsemana.com                1111\neltiempo.com               660\nmariafernandacabal.com     544\nfacebook.com               467\nbluradio.com               258\ntwitter.com                249\nlafm.com.co                240\now.ly                      228\nelcolombiano.com           220\nyoutu.be                   207\nyoutube.com                205\ncentrodemocratico.com      192\nln.is                      179\nrcnradio.com               177\nwradio.com.co              176\ninstagram.com              176\ncaracol.com.co             175\nelespectador.com           175\ncostanoticias.com          153\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\ncolumna                  481\nsoycabal                 433\nlascosascomoson          196\n100porcientocabal        129\nenvivo                   123\nsoyopositor              122\natención                 120\nvotacd100cabal           118\nalaire                   107\nfarc                      93\nrecomendado               86\nrestituciónsindespojo     77\nurgente                   73\nbogotá                    67\ncolombia                  65\nvocesysonidos             61\nopinión                   60\ncomunidad                 57\nmañanasblu                57\nvenezuela                 55\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nalvarouribevel     507\njorenvilla1        393\njuanmansantos      326\neltiempo           314\npetrogustavo       310\ndrvargasquemba     301\nigonima            295\ncedemocratico      268\nbluradioco         265\nrcnlaradio         236\nrevistasemana      234\npoliciacolombia    225\nelespectador       218\njflafaurie         208\nricardopuentesm    201\ncol_ejercito       189\nalirestrepo        169\nnoticiasrcn        161\nfiscaliacol        158\nyobusgo            157\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nq              3678\nfarc           2630\ncolombia       2396\npaz            2222\nd              2188\ngobierno       1317\npaís           1240\nsantos         1104\ngracias         850\npetro           841\njusticia        816\nvenezuela       784\nuribe           770\nbogotá          759\nlibertad        716\nvíctimas        708\naños            708\ncolumna         704\npresidente      687\ncolombianos     633\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n10    2424\n12    2238\n11    2224\n09    2190\n08    2136\n20    1822\n18    1815\n13    1813\n21    1788\n14    1756\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for iPhone             14186\nTwitter for BlackBerry®         8291\nTwitter for Android             5049\nTwitter Web Client              2627\nTwitter for BlackBerry           841\nTweetDeck                        396\nTwitter for iPad                 239\nTwitter for  Android             207\nInstagram                        167\nTwitter Web App                   94\nPeriscope                         84\nJetpack.com                       75\nTwitter for Android Tablets       73\nTwitter Media Studio              73\nTwitter for Websites              19\nTwitter for Windows Phone         18\niOS                               10\nTwitlonger                         4\nerased5423693                      4\nMobile Web (M2)                    3\nTwiffo                             1\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con el 20% del total de tópicos generados\n\n\nCode\n# calculate the 20% from the total of topics\nnum_topics = len(topic_model.get_topic_info())\nper_topics = int(num_topics * 20 / 100)\n\n\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=per_topics)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=per_topics)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [10]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @MariaFdaCabal, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 32462 tweets de @MariaFdaCabal, alrededor de 725 hablan sobre temas de género, es decir, cerca del 2.23%\nLista de palabras en tópicos [10]:\n['mujeres', 'negros', 'mujer', 'gay', 'aborto', 'negras', 'homosexuales', 'gays', 'comunidades', 'niñas']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/brasilsemaborto.html",
    "href": "pages/brasilsemaborto.html",
    "title": "Análisis de tweets de @brasilsemaborto",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2009-07-31 18:19:18-03:00 / 2023-01-01 10:45:02-03:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1411 entries, 199416 to 200826\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                            \n---  ------                   --------------  -----                            \n 0   query                    1411 non-null   object                           \n 1   id                       1411 non-null   float64                          \n 2   timestamp_utc            1411 non-null   int64                            \n 3   local_time               1411 non-null   object                           \n 4   user_screen_name         1411 non-null   object                           \n 5   text                     1411 non-null   object                           \n 6   possibly_sensitive       623 non-null    object                           \n 7   retweet_count            1411 non-null   float64                          \n 8   like_count               1411 non-null   float64                          \n 9   reply_count              1411 non-null   float64                          \n 10  impression_count         10 non-null     object                           \n 11  lang                     1411 non-null   object                           \n 12  to_username              281 non-null    object                           \n 13  to_userid                281 non-null    float64                          \n 14  to_tweetid               254 non-null    float64                          \n 15  source_name              1411 non-null   object                           \n 16  source_url               1411 non-null   object                           \n 17  user_location            1411 non-null   object                           \n 18  lat                      9 non-null      object                           \n 19  lng                      9 non-null      object                           \n 20  user_id                  1411 non-null   object                           \n 21  user_name                1411 non-null   object                           \n 22  user_verified            1411 non-null   float64                          \n 23  user_description         1411 non-null   object                           \n 24  user_url                 1411 non-null   object                           \n 25  user_image               1411 non-null   object                           \n 26  user_tweets              1411 non-null   object                           \n 27  user_followers           1411 non-null   float64                          \n 28  user_friends             1411 non-null   object                           \n 29  user_likes               1411 non-null   float64                          \n 30  user_lists               1411 non-null   float64                          \n 31  user_created_at          1411 non-null   object                           \n 32  user_timestamp_utc       1411 non-null   float64                          \n 33  collected_via            1411 non-null   object                           \n 34  match_query              1411 non-null   float64                          \n 35  retweeted_id             0 non-null      float64                          \n 36  retweeted_user           0 non-null      float64                          \n 37  retweeted_user_id        0 non-null      float64                          \n 38  retweeted_timestamp_utc  0 non-null      object                           \n 39  quoted_id                6 non-null      object                           \n 40  quoted_user              6 non-null      object                           \n 41  quoted_user_id           6 non-null      float64                          \n 42  quoted_timestamp_utc     6 non-null      float64                          \n 43  collection_time          1411 non-null   object                           \n 44  url                      1411 non-null   object                           \n 45  place_country_code       15 non-null     object                           \n 46  place_name               15 non-null     object                           \n 47  place_type               15 non-null     object                           \n 48  place_coordinates        15 non-null     object                           \n 49  links                    433 non-null    object                           \n 50  domains                  433 non-null    object                           \n 51  media_urls               326 non-null    object                           \n 52  media_files              326 non-null    object                           \n 53  media_types              326 non-null    object                           \n 54  media_alt_texts          21 non-null     object                           \n 55  mentioned_names          207 non-null    object                           \n 56  mentioned_ids            197 non-null    object                           \n 57  hashtags                 638 non-null    object                           \n 58  intervention_type        0 non-null      float64                          \n 59  intervention_text        0 non-null      float64                          \n 60  intervention_url         0 non-null      float64                          \n 61  country                  1411 non-null   object                           \n 62  date                     1411 non-null   datetime64[ns, America/Sao_Paulo]\ndtypes: datetime64[ns, America/Sao_Paulo](1), float64(20), int64(1), object(41)\nmemory usage: 705.5+ KB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\nbit.ly                                                                    94\nbrasilsemaborto.org                                                       87\nyoutube.com                                                               30\nyoutu.be                                                                  29\nwp.me                                                                     28\ninstagram.com                                                             24\nfacebook.com                                                              19\ntwitpic.com                                                               19\nbrasilsemaborto.com.br                                                    11\ngazetadopovo.com.br                                                        8\ncamara.leg.br                                                              8\nwww12.senado.gov.br                                                        8\ntwitpic.com|twitpic.com                                                    4\nfb.me                                                                      3\nitaucinemas.com.br                                                         3\nbrasilsemaborto.wordpress.com                                              3\nveja.abril.com.br                                                          3\nbrasilsemaborto.org|twitter.com|facebook.com|instagram.com|youtube.com     3\nnoticias.cancaonova.com                                                    3\nwww12.senado.leg.br                                                        3\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\nbrasilsemaborto          271\nmarchavirtualpelavida     87\ncodigopenal               73\nstfabortonao              71\npelas2vidas               61\nmulhersimabortonao        35\nmarchapelavida            33\nabortoépreconceito        33\nasduasvidasimportam       33\n10anos                    30\nestatutodonascituro       28\nafavordavida              24\nbrasilpelasduasvidas      16\nverdadepelavida           16\navidadependedoseuvoto     15\nsimàvida                  12\ndiadonascituro            10\nanencefalo                 9\navidaporumfio              9\nstfdiganaoaoaborto         7\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nlenisegarcia       41\nbrasilsemaborto    29\naddthis             8\nrebeccakiesslin     6\nstf_oficial         6\nanabeatrizries      5\nmpf_pgr             4\ncnnoticias          4\nluh_lena            4\nanadep_brasil       4\ngazetadopovo        4\njorgeferraz         4\nveja                3\nalosenado           3\nwagnermoura         3\nangela_gandra       3\njornaldacbn         3\naddtoany            2\nagenciacamara       2\neunicio             2\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Portuguese\nnlp = spacy.load(\"pt_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nvida                     494\naborto                   306\nbrasilsemaborto          274\nmarcha                   165\nbrasil                   131\nnacional                 110\ndia                      109\nmarchavirtualpelavida     88\nmovimento                 85\nnascituro                 77\nparticipe                 74\ncodigopenal               73\nmãe                       71\ndefesa                    71\nstfabortonao              70\nhoje                      66\nestatuto                  65\ncódigo                    64\nsaiba                     63\nacompanhe                 60\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n11    193\n10    161\n16    130\n15    128\n19    111\n12    106\n09     94\n17     91\n14     72\n18     57\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for Android            479\nTwitter Web Client             453\nPlume for Android              161\nTwitter Web App                 89\nTwitter for iPhone              60\nTweetDeck                       42\nJetpack.com                     41\nTwitter for Websites            26\nTweetCaster for Android         18\nPosterous                       16\nGravity                         15\nTwitter for Android Tablets      7\nGravity!                         2\nTwibbon                          1\nTwitpic                          1\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=25)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [2, 3, 7]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @brasilsemaborto, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 1411 tweets de @brasilsemaborto, alrededor de 1027 hablan sobre temas de género, es decir, cerca del 72.79%\nLista de palabras en tópicos [2, 3, 7]:\n['brasil', 'aborto', 'movimento', 'presidente', 'brasilsemaborto', 'legalização', 'vida', 'campanha', 'defesa', 'lenise', 'aborto', 'psol', 'stfabortonao', 'ação', 'abortar', 'gestação', 'abortoépreconceito', 'via', 'gravidez', 'legalização', 'mulhersimabortonao', 'mulher', 'mulheres', 'brasilsemaborto', 'via', 'precisa', 'parabéns', 'vamos', 'informação', 'viva']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/etorrescobo.html",
    "href": "pages/etorrescobo.html",
    "title": "Análisis de tweets de @etorrescobo",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2010-07-06 10:37:00-05:00 / 2023-03-21 09:58:42-05:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 8314 entries, 10617 to 18930\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                            \n---  ------                   --------------  -----                            \n 0   query                    8314 non-null   object                           \n 1   id                       8314 non-null   float64                          \n 2   timestamp_utc            8314 non-null   int64                            \n 3   local_time               8314 non-null   object                           \n 4   user_screen_name         8314 non-null   object                           \n 5   text                     8314 non-null   object                           \n 6   possibly_sensitive       2818 non-null   object                           \n 7   retweet_count            8314 non-null   float64                          \n 8   like_count               8314 non-null   float64                          \n 9   reply_count              8314 non-null   float64                          \n 10  impression_count         243 non-null    object                           \n 11  lang                     8314 non-null   object                           \n 12  to_username              2188 non-null   object                           \n 13  to_userid                2188 non-null   float64                          \n 14  to_tweetid               2120 non-null   float64                          \n 15  source_name              8314 non-null   object                           \n 16  source_url               8314 non-null   object                           \n 17  user_location            8314 non-null   object                           \n 18  lat                      65 non-null     object                           \n 19  lng                      65 non-null     object                           \n 20  user_id                  8314 non-null   object                           \n 21  user_name                8314 non-null   object                           \n 22  user_verified            8314 non-null   float64                          \n 23  user_description         8314 non-null   object                           \n 24  user_url                 8314 non-null   object                           \n 25  user_image               8314 non-null   object                           \n 26  user_tweets              8314 non-null   object                           \n 27  user_followers           8314 non-null   float64                          \n 28  user_friends             8314 non-null   object                           \n 29  user_likes               8314 non-null   float64                          \n 30  user_lists               8314 non-null   float64                          \n 31  user_created_at          8314 non-null   object                           \n 32  user_timestamp_utc       8314 non-null   float64                          \n 33  collected_via            8314 non-null   object                           \n 34  match_query              8314 non-null   float64                          \n 35  retweeted_id             0 non-null      float64                          \n 36  retweeted_user           0 non-null      float64                          \n 37  retweeted_user_id        0 non-null      float64                          \n 38  retweeted_timestamp_utc  0 non-null      object                           \n 39  quoted_id                800 non-null    object                           \n 40  quoted_user              800 non-null    object                           \n 41  quoted_user_id           800 non-null    float64                          \n 42  quoted_timestamp_utc     800 non-null    float64                          \n 43  collection_time          8314 non-null   object                           \n 44  url                      8314 non-null   object                           \n 45  place_country_code       672 non-null    object                           \n 46  place_name               672 non-null    object                           \n 47  place_type               672 non-null    object                           \n 48  place_coordinates        672 non-null    object                           \n 49  links                    1660 non-null   object                           \n 50  domains                  1660 non-null   object                           \n 51  media_urls               1812 non-null   object                           \n 52  media_files              1812 non-null   object                           \n 53  media_types              1812 non-null   object                           \n 54  media_alt_texts          249 non-null    object                           \n 55  mentioned_names          4040 non-null   object                           \n 56  mentioned_ids            3764 non-null   object                           \n 57  hashtags                 1824 non-null   object                           \n 58  intervention_type        0 non-null      float64                          \n 59  intervention_text        0 non-null      float64                          \n 60  intervention_url         0 non-null      float64                          \n 61  country                  8314 non-null   object                           \n 62  date                     8314 non-null   datetime64[ns, America/Guayaquil]\ndtypes: datetime64[ns, America/Guayaquil](1), float64(20), int64(1), object(41)\nmemory usage: 4.1+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\netorrescobo.com             241\ntinyurl.com                 141\ninstagram.com               120\nbit.ly                       85\nyoutu.be                     64\nelcomercio.com               64\nyoutube.com                  52\nabc.es                       52\nft.com                       46\neluniverso.com               40\nelpais.com                   36\now.ly                        30\nfacebook.com                 25\nmedium.com                   24\nexpreso.ec                   23\nwsj.com                      23\ntwitter.com                  20\ninternacional.elpais.com     16\nhoy.com.ec                   13\nnyti.ms                      12\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\necuador                   213\nambato                    163\ntungurahua                116\nquito                      47\nvenezuela                  43\nasambleanacional           35\nmaduro                     29\ntrump                      26\nespaña                     24\nvota6                      23\natención                   21\ncoip                       20\nemprendersinobstáculos     19\nusfq                       16\ncolombia                   16\nbrexit                     15\nestebantorres              14\ncambio                     14\necuadorprotesta            14\ntoros                      13\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nasambleaecuador    235\nestebanperezm      140\netorrescobo        133\nlftorrest           86\nlassoguillermo      74\nbancadapsc          66\neluniversocom       62\nrxandrade           57\nel_pais             52\nusfq_ecuador        48\njfcarpio            47\ncambioec            43\nabc_es              42\namandahidalgoa      39\nxvillalba1          39\necuavisa            37\ncristiano           35\nla6ecuador          35\nyoutube             33\nlenin               31\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Spanish\nnlp = spacy.load(\"es_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\necuador         586\ngracias         388\ngobierno        343\nvía             332\nasamblea        298\nsaludos         280\npaís            274\nambato          265\npresidente      259\nley             251\nartículo        221\nnacional        216\nthe             203\necuatorianos    178\ntungurahua      173\ncomparto        167\naños            161\ndebate          152\nvida            152\nquito           150\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n11    633\n10    587\n12    578\n17    571\n20    552\n09    503\n13    502\n21    490\n16    469\n18    451\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter for iPhone         4322\nTwitter Web Client         1787\nTwitter for iPad            704\nTwitter for Android         432\nTwitter for BlackBerry®     344\nTwitter Web App             232\nTwitter for Websites        229\nInstagram                   105\nKioskoymas                   41\nAgorapulse app               33\nMobile Web                   17\nMedium                       17\niOS                          14\nHootsuite Inc.               13\nTweetChat                     6\nKindle                        5\nCanva                         5\nFOX News Login                2\nPhotos on iOS                 2\nOS X                          1\nInstagram on iOS              1\nCrowdfire Inc.                1\nbitly bitlink                 1\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con 10 tópicos del contenido de los tweets\n\n\nCode\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=31)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=31)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [7]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de @etorrescobo, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 8314 tweets de @etorrescobo, alrededor de 542 hablan sobre temas de género, es decir, cerca del 6.52%\nLista de palabras en tópicos [7]:\n['aborto', 'mujeres', 'violación', 'matrimonio', 'feminismo', 'despenalización', 'mujer', 'derecho', 'vida', 'coip']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  },
  {
    "objectID": "pages/pastormalafaia.html",
    "href": "pages/pastormalafaia.html",
    "title": "Análisis de tweets de @PastorMalafaia",
    "section": "",
    "text": "Datos\nInformación general sobre la base de datos\n\n\nCode\nmin_date = df['date'].min()\n\nmax_date = df['date'].max()\n\nprint(f\"\\nPeriodo de tweets recolectados: {min_date} / {max_date}\\n\")\n\n\n\nPeriodo de tweets recolectados: 2010-06-11 11:27:43-03:00 / 2023-03-20 08:00:26-03:00\n\n\n\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 43709 entries, 45185 to 88893\nData columns (total 63 columns):\n #   Column                   Non-Null Count  Dtype                            \n---  ------                   --------------  -----                            \n 0   query                    43709 non-null  object                           \n 1   id                       43709 non-null  float64                          \n 2   timestamp_utc            43709 non-null  int64                            \n 3   local_time               43709 non-null  object                           \n 4   user_screen_name         43709 non-null  object                           \n 5   text                     43709 non-null  object                           \n 6   possibly_sensitive       26733 non-null  object                           \n 7   retweet_count            43709 non-null  float64                          \n 8   like_count               43709 non-null  float64                          \n 9   reply_count              43709 non-null  float64                          \n 10  impression_count         365 non-null    object                           \n 11  lang                     43709 non-null  object                           \n 12  to_username              874 non-null    object                           \n 13  to_userid                874 non-null    float64                          \n 14  to_tweetid               560 non-null    float64                          \n 15  source_name              43709 non-null  object                           \n 16  source_url               43709 non-null  object                           \n 17  user_location            43709 non-null  object                           \n 18  lat                      0 non-null      object                           \n 19  lng                      0 non-null      object                           \n 20  user_id                  43709 non-null  object                           \n 21  user_name                43709 non-null  object                           \n 22  user_verified            43709 non-null  float64                          \n 23  user_description         43709 non-null  object                           \n 24  user_url                 43709 non-null  object                           \n 25  user_image               43709 non-null  object                           \n 26  user_tweets              43709 non-null  object                           \n 27  user_followers           43709 non-null  float64                          \n 28  user_friends             43709 non-null  object                           \n 29  user_likes               43709 non-null  float64                          \n 30  user_lists               43709 non-null  float64                          \n 31  user_created_at          43709 non-null  object                           \n 32  user_timestamp_utc       43709 non-null  float64                          \n 33  collected_via            43709 non-null  object                           \n 34  match_query              43709 non-null  float64                          \n 35  retweeted_id             0 non-null      float64                          \n 36  retweeted_user           0 non-null      float64                          \n 37  retweeted_user_id        0 non-null      float64                          \n 38  retweeted_timestamp_utc  0 non-null      object                           \n 39  quoted_id                53 non-null     object                           \n 40  quoted_user              53 non-null     object                           \n 41  quoted_user_id           53 non-null     float64                          \n 42  quoted_timestamp_utc     53 non-null     float64                          \n 43  collection_time          43709 non-null  object                           \n 44  url                      43709 non-null  object                           \n 45  place_country_code       21 non-null     object                           \n 46  place_name               21 non-null     object                           \n 47  place_type               21 non-null     object                           \n 48  place_coordinates        21 non-null     object                           \n 49  links                    20062 non-null  object                           \n 50  domains                  20062 non-null  object                           \n 51  media_urls               10154 non-null  object                           \n 52  media_files              10154 non-null  object                           \n 53  media_types              10154 non-null  object                           \n 54  media_alt_texts          399 non-null    object                           \n 55  mentioned_names          3473 non-null   object                           \n 56  mentioned_ids            3149 non-null   object                           \n 57  hashtags                 2265 non-null   object                           \n 58  intervention_type        0 non-null      float64                          \n 59  intervention_text        0 non-null      float64                          \n 60  intervention_url         0 non-null      float64                          \n 61  country                  43709 non-null  object                           \n 62  date                     43709 non-null  datetime64[ns, America/Sao_Paulo]\ndtypes: datetime64[ns, America/Sao_Paulo](1), float64(20), int64(1), object(41)\nmemory usage: 21.3+ MB\n\n\n\n\nDominios\nLista del top 20 de otros sitios web mencionados en los tweets y su frecuencia\n\n\nCode\n# count items on column\ndomains_list = df['domains'].value_counts()\n\n# return first n rows in descending order\ntop_domains = domains_list.nlargest(20)\n\ntop_domains\n\n\ndomains\nyoutu.be                       7145\nverdadegospel.com              3659\nyoutube.com                    2116\ngoo.gl                         1719\nveja.abril.com.br               992\nvitoriaemcristo.org             848\nmigre.me                        696\neditoracentralgospel.com        336\nbit.ly                          166\ninstagram.com                   153\ngospelplay.com                  147\nfacebook.com                    140\nfacebook.com|youtube.com        123\npastoresjuntos.com              111\neventos.vitoriaemcristo.org     103\nfb.watch|instagram.com          103\nescoladelideresonline.com        69\ng1.globo.com                     67\nadvec.org                        67\neventospastorsilas.com.br        66\nName: count, dtype: int64\n\n\n\n\nHashtags\nLista del top 20 de hashtags más usados y su frecuencia\n\n\nCode\n# convert dataframe column to list\nhashtags = df['hashtags'].to_list()\n\n# remove nan items from list\nhashtags = [x for x in hashtags if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nhashtags = [x.split('|') for x in hashtags]\n\n# flatten list of lists\nhashtags = [item for sublist in hashtags for item in sublist]\n\n# count items on list\nhashtags_count = pd.Series(hashtags).value_counts()\n\n# return first n rows in descending order\ntop_hashtags = hashtags_count.nlargest(20)\n\ntop_hashtags\n\n\nsilasmalafaia                       203\nroubalheiraepttudoaver              197\ndilmavaiperderaecio45vencer         123\nelessabiamdorouboforadilma          116\n12anosderoubalheiradoptchega         71\npovobrasileirocontradilmaept         70\nchegaderoubalheiraforadilma          69\n225                                  60\nchegaderouboementiraforadilma        59\ndilmanaodialoguecomterrorista        54\nclamandopelobrasil                   52\ndilmaroubalheiraepttudoaver          52\nfachinnão                            46\nnemcorrupçãonemptnemdilma            43\nvideodepregacao                      43\nrespond                              43\naovivocommalafaia                    42\nlulaedilmamenosodiocontramarina      42\nvotoaeciopelobr45il                  41\nmarinaresistentevaiserpresidente     39\nName: count, dtype: int64\n\n\n\n\nUsuarios\nTop 20 de usuarios más mencionados en los tweets\n\n\nCode\n# filter column from dataframe\nusers = df['mentioned_names'].to_list()\n\n# remove nan items from list\nusers = [x for x in users if not pd.isna(x)]\n\n# split items into a list based on a delimiter\nusers = [x.split('|') for x in users]\n\n# flatten list of lists\nusers = [item for sublist in users for item in sublist]\n\n# count items on list\nusers_count = pd.Series(users).value_counts()\n\n# return first n rows in descending order\ntop_users = users_count.nlargest(20)\n\ntop_users\n\n\nverdadegospel            638\nadvecoficial             532\nedcentralgospel          179\nreinaldoazevedo          158\navec_oficial             135\nelizetemalafaia          115\nradaronline              103\neyshila1                  70\ncgospelmusic              60\npastormalafaiaoficial     52\npastormalafaia            45\nnani_azevedo              43\ndrmikemurdock             41\nsilasmalafaia             39\nveja                      38\njozyanneoficial           37\nmagnomaltaofc             35\nadvecsaopaulo             33\npgm_ratinho               26\ndanilogentili             23\nName: count, dtype: int64\n\n\n\n\nLikes en el tiempo\n\n\nCode\n# plot the data using plotly\nfig = px.line(df, \n              x='date', \n              y='like_count', \n              title='Likes over Time',\n              template='plotly_white', \n              hover_data=['text'])\n\n# show the plot\nfig.show()\n\n\n\n                                                \n\n\n\n\nTokens\nLista del top 20 de los tokens más comunes y su frecuencia\n\n\nCode\n# load the spacy model for Portuguese\nnlp = spacy.load(\"pt_core_news_sm\")\n\n# load stop words for Spanish\nSTOP_WORDS = nlp.Defaults.stop_words\n\n# Function to filter stop words\ndef filter_stopwords(text):\n    # lower text\n    doc = nlp(text.lower())\n    # filter tokens\n    tokens = [token.text for token in doc if not token.is_stop and token.text not in STOP_WORDS and token.is_alpha]\n    return ' '.join(tokens)\n\n# apply function to dataframe column\ndf['text_pre'] = df['text'].apply(filter_stopwords)\n\n# count items on column\ntoken_counts = df[\"text_pre\"].str.split(expand=True).stack().value_counts()[:20]\n\ntoken_counts\n\n\nassista       7856\nq             5381\nvídeo         4499\ndeus          3435\nprograma      3030\ndia           2894\nbolsonaro     2840\nvitória       2782\ncristo        2620\nbrasil        2418\nacesse        2256\nhoje          2189\nvou           2168\npt            2073\ndivulgue      1981\nñ             1882\nsábado        1816\nimprensa      1727\nlula          1721\nimperdível    1715\nName: count, dtype: int64\n\n\n\n\nHoras\nLista de las 10 horas con más cantidad de tweets publicados\n\n\nCode\n# extract hour from datetime column\ndf['hour'] = df['date'].dt.strftime('%H')\n\n# count items on column\nhours_count = df['hour'].value_counts()\n\n# return first n rows in descending order\ntop_hours = hours_count.nlargest(10)\n\ntop_hours\n\n\nhour\n17    3772\n12    3693\n14    3432\n15    3366\n16    3268\n10    3017\n11    3004\n13    2849\n18    2446\n19    2377\nName: count, dtype: int64\n\n\n\n\nPataformas\nPlataformas desde las que se publicaron contenidos y su frecuencia\n\n\nCode\ndf['source_name'].value_counts()\n\n\nsource_name\nTwitter Web Client                 11191\nPostcron App                       10752\nTwitter for iPad                    8900\nmLabs - Gestão de Redes Sociais     7243\nTwitter for iPhone                  2183\nerased3412752                        723\nTwitter Ads                          580\nTwitter for Android                  466\nTwitter for Android Tablets          444\nTweetDeck                            424\nTwitter Web App                      303\nPostgrain                            144\nPeriscope                            106\nTwitter for BlackBerry®               98\nTwitter for Advertisers.              65\nDynamic Tweets                        63\nTwitpic                                7\nTwitter for Websites                   3\nMobile Web                             3\niOS                                    3\nMobile Web (M2)                        2\nInstagram                              2\nPhotos on iOS                          1\nTwitter Media Studio                   1\naudioBoom                              1\nTwitter for Windows Phone              1\nName: count, dtype: int64\n\n\n\n\nTópicos\nTécnica de modelado de tópicos con transformers y TF-IDF\n\n\nCode\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER)\ndf['text_pre'] = df['text_pre'].apply(lambda x: p.clean(x))\n\n# replace emojis with descriptions\ndf['text_pre'] = df['text_pre'].apply(lambda x: demojize(x))\n\n# filter column\ndocs = df['text_pre']\n\n# calculate topics and probabilities\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True)\n\n# training\ntopics, probs = topic_model.fit_transform(docs)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n                                                \n\n\n\n\nReducción de tópicos\nMapa con el 20% del total de tópicos generados\n\n\nCode\n# calculate the 20% from the total of topics\nnum_topics = len(topic_model.get_topic_info())\nper_topics = int(num_topics * 20 / 100)\n\n# reduce the number of topics\ntopic_model.reduce_topics(docs, nr_topics=per_topics)\n\n# visualize topics\ntopic_model.visualize_topics()\n\n\n\n                                                \n\n\n\n\nTérminos por tópico\n\n\nCode\ntopic_model.visualize_barchart(top_n_topics=per_topics)\n\n\n\n                                                \n\n\n\n\nAnálisis de tópicos\nSelección de tópicos que tocan temas de género\n\n\nCode\n# selection of topics\ntopics = [4, 30, 40, 120]\n\nkeywords_list = []\nfor topic_ in topics:\n    topic = topic_model.get_topic(topic_)\n    keywords = [x[0] for x in topic]\n    keywords_list.append(keywords)\n\n# flatten list of lists\nwords_list = [item for sublist in keywords_list for item in sublist]\n\n# use apply method with lambda function to filter rows\nfiltered_df = df[df['text_pre'].apply(lambda x: any(word in x for word in words_list))]\n\npercentage = round(100 * len(filtered_df) / len(df), 2)\nprint(f\"Del total de {len(df)} tweets de  @PastorMalafaia, alrededor de {len(filtered_df)} hablan sobre temas de género, es decir, cerca del {percentage}%\")\n\nprint(f\"Lista de palabras en tópicos {topics}:\\n{words_list}\")\n\n\nDel total de 43709 tweets de  @PastorMalafaia, alrededor de 7590 hablan sobre temas de género, es decir, cerca del 17.36%\nLista de palabras en tópicos [4, 30, 40, 120]:\n['gay', 'ativismo', 'gays', 'ativistas', 'homofobia', 'parada', 'causa', 'kit', 'jurídica', 'manobra', 'aborto', 'anencéfalos', 'útero', 'mobilização', 'bebê', 'envie', 'prolongamento', 'concepção', 'emails', 'mãe', 'gênero', 'ideologia', 'mulheres', 'prefeitura', 'constrangimento', 'mulher', 'implantada', 'rio', 'feministas', 'estupro', 'trans', 'transexual', 'liga', 'mamaria', 'feminina', 'cirurgia', 'prótese', 'reais', 'vôlei', 'mulher']\n\n\n\n\nCode\n# drop rows with 0 values in two columns\nfiltered_df = filtered_df[(filtered_df.like_count != 0) & (filtered_df.retweet_count != 0)]\n\n# add a new column with the sum of two columns\nfiltered_df['impressions'] = (filtered_df['like_count'] + filtered_df['retweet_count'])/2\n\n# extract year from datetime column\nfiltered_df['year'] = filtered_df['date'].dt.year\n\n# remove urls, mentions, hashtags and numbers\np.set_options(p.OPT.URL)\nfiltered_df['tweet_text'] = filtered_df['text'].apply(lambda x: p.clean(x))\n\n# Create scatter plot\nfig = px.scatter(filtered_df, x='like_count', \n                 y='retweet_count',\n                 size='impressions', \n                 color='year',\n                 hover_name='tweet_text')\n\n# Update title and axis labels\nfig.update_layout(\n    title='Tweets talking about gender with most Likes and Retweets',\n    xaxis_title='Number of Likes',\n    yaxis_title='Number of Retweets'\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nTópicos en el tiempo\n\n\nCode\n# convert column to list\ntweets = df['text_pre'].to_list()\ntimestamps = df['local_time'].to_list()\n\ntopics_over_time = topic_model.topics_over_time(docs=tweets, \n                                                timestamps=timestamps, \n                                                global_tuning=True, \n                                                evolution_tuning=True, \n                                                nr_bins=20)\n\ntopic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
  }
]